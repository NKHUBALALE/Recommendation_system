{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load your anime data\n",
    "anime_data_path = 'csv files/anime_cleaned.csv'\n",
    "anime_data = pd.read_csv(anime_data_path)\n",
    "\n",
    "# Ensure anime_data includes an 'anime_id' column\n",
    "if 'anime_id' not in anime_data.columns:\n",
    "    raise ValueError(\"The anime_data DataFrame must include an 'anime_id' column.\")\n",
    "\n",
    "# Create a TF-IDF vectorizer and fit it to the anime genres\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(anime_data['genre'])\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Save the content-based model and similarity matrix with gzip compression\n",
    "with gzip.open('content_based_model.pkl.gz', 'wb') as f:\n",
    "    pickle.dump((vectorizer, cosine_sim, anime_data), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "(12294, 12294)\n",
      "   anime_id                              name  \\\n",
      "0     32281                    Kimi no Na wa.   \n",
      "1      5114  Fullmetal Alchemist: Brotherhood   \n",
      "2     28977                          GintamaÂ°   \n",
      "3      9253                       Steins;Gate   \n",
      "4      9969                     Gintama&#039;   \n",
      "\n",
      "                                               genre   type  episodes  rating  \\\n",
      "0               Drama, Romance, School, Supernatural  Movie       1.0    9.37   \n",
      "1  Action, Adventure, Drama, Fantasy, Magic, Mili...     TV      64.0    9.26   \n",
      "2  Action, Comedy, Historical, Parody, Samurai, S...     TV      51.0    9.25   \n",
      "3                                   Sci-Fi, Thriller     TV      24.0    9.17   \n",
      "4  Action, Comedy, Historical, Parody, Samurai, S...     TV      51.0    9.16   \n",
      "\n",
      "   members  \n",
      "0   200630  \n",
      "1   793665  \n",
      "2   114262  \n",
      "3   673572  \n",
      "4   151266  \n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def load_content_based_model(file_path):\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        vectorizer, cosine_sim, anime_data = pickle.load(f)\n",
    "    return vectorizer, cosine_sim, anime_data\n",
    "\n",
    "# Load the model\n",
    "vectorizer, cosine_sim, anime_data = load_content_based_model('content_based_model.pkl.gz')\n",
    "\n",
    "# Check if the data was loaded correctly\n",
    "print(type(vectorizer))\n",
    "print(cosine_sim.shape)\n",
    "print(anime_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       anime_id                                               name  rating\n",
      "0         32281                                     Kimi no Na wa.    9.37\n",
      "1          5114                   Fullmetal Alchemist: Brotherhood    9.26\n",
      "3          9253                                        Steins;Gate    9.17\n",
      "10464     33662            Taka no Tsume 8: Yoshida-kun no X-Files   10.00\n",
      "11        28851                                     Koe no Katachi    9.05\n",
      "7           820                               Ginga Eiyuu Densetsu    9.11\n",
      "45         4282                     Kara no Kyoukai 5: Mujun Rasen    8.68\n",
      "15          199                      Sen to Chihiro no Kamikakushi    8.93\n",
      "5         32935  Haikyuu!!: Karasuno Koukou VS Shiratorizawa Ga...    9.15\n",
      "10         4181                               Clannad: After Story    9.06\n"
     ]
    }
   ],
   "source": [
    "def get_recommendations(user_animes, anime_data, cosine_sim, top_n=10, rating_weight=0.5):\n",
    "    # Ensure user_animes are valid\n",
    "    valid_animes = anime_data[anime_data['name'].isin(user_animes)]\n",
    "    if valid_animes.empty:\n",
    "        raise ValueError(\"None of the user-provided anime titles were found in the dataset.\")\n",
    "    \n",
    "    # Initialize similarity scores\n",
    "    similar_scores = pd.Series(0, index=anime_data.index)\n",
    "    \n",
    "    # Calculate similarity scores for user-provided animes\n",
    "    for anime in user_animes:\n",
    "        if anime in anime_data['name'].values:\n",
    "            idx = anime_data.index[anime_data['name'] == anime].tolist()[0]\n",
    "            similar_scores += pd.Series(cosine_sim[idx])\n",
    "    \n",
    "    # Add similarity scores and ratings to recommendations\n",
    "    recommendations = anime_data.copy()\n",
    "    recommendations['similarity'] = similar_scores\n",
    "    recommendations['rating'] = recommendations['rating'].astype(float)\n",
    "    \n",
    "    # Compute combined score\n",
    "    recommendations['combined_score'] = (recommendations['similarity'] * (1 - rating_weight) + \n",
    "                                          recommendations['rating'] * rating_weight)\n",
    "    \n",
    "    # Sort by combined score\n",
    "    recommendations = recommendations.sort_values(by='combined_score', ascending=False)\n",
    "    \n",
    "    # Return top N recommendations including anime ID\n",
    "    top_recommendations = recommendations.head(top_n)[['anime_id', 'name', 'rating']]\n",
    "    return top_recommendations\n",
    "\n",
    "# Example usage with loaded model\n",
    "user_animes = ['Fullmetal Alchemist: Brotherhood', 'Steins;Gate', 'Kimi no Na wa.']\n",
    "recommendations = get_recommendations(user_animes, anime_data, cosine_sim)\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved content_based_model_chunks\\chunk_000.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_001.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_002.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_003.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_004.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_005.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_006.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_007.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_008.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_009.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_010.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_011.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_012.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_013.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_014.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_015.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_016.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_017.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_018.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_019.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_020.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_021.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_022.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_023.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_024.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_025.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_026.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_027.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_028.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_029.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_030.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_031.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_032.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_033.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_034.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_035.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_036.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_037.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_038.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_039.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_040.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_041.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_042.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_043.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_044.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_045.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_046.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_047.pkl.gz with size 24.00 MB\n",
      "Saved content_based_model_chunks\\chunk_048.pkl.gz with size 2.06 MB\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "\n",
    "def split_file(input_file, output_dir, chunk_size_mb=24):\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Check if the input file exists\n",
    "    if not os.path.isfile(input_file):\n",
    "        raise FileNotFoundError(f\"Input file not found: {input_file}\")\n",
    "    \n",
    "    # Read the content of the original file\n",
    "    with gzip.open(input_file, 'rb') as f:\n",
    "        file_content = f.read()\n",
    "    \n",
    "    # Split the content into chunks\n",
    "    chunk_size = chunk_size_mb * 1024 * 1024  # Convert MB to bytes\n",
    "    num_chunks = (len(file_content) + chunk_size - 1) // chunk_size  # Calculate number of chunks\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        start = i * chunk_size\n",
    "        end = min(start + chunk_size, len(file_content))\n",
    "        chunk_data = file_content[start:end]\n",
    "        \n",
    "        chunk_file = os.path.join(output_dir, f'chunk_{i:03}.pkl.gz')\n",
    "        with gzip.open(chunk_file, 'wb') as f:\n",
    "            f.write(chunk_data)\n",
    "        \n",
    "        print(f'Saved {chunk_file} with size {len(chunk_data) / (1024 * 1024):.2f} MB')\n",
    "\n",
    "# Example usage\n",
    "input_file = 'content_based_model.pkl.gz'\n",
    "output_dir = 'content_based_model_chunks'\n",
    "split_file(input_file, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Classification_sprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
